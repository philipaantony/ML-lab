"
Experiment No.: 1
Aim
Write a program to perform matrix operations. Use numpy as the python library and perform the
operation using built in functions in Numpy.
CO1
Use different python packages to perform numerical calculations, statistical computations and data
visualization.
Procedure
import numpy as np
def inputMatrix(matrix_name,row,col):
 mat=[]
 print(f""enter the elements for the {matrix_name}"")
 for i in range(row):
 mat1=[]
 for j in range(col):
 n=int(input(f""enter the row {i+1} and column {j+1}""))
 mat1.append(n)
 mat.append(mat1)
 return np.array(mat)
row=int(input(""enter the number of rows""))
col=int(input(""enter the number of column""))
matrix1=inputMatrix(""matrix1"",row,col)
matrix2 = inputMatrix(""matrix2"",row,col)
print(matrix1)
print(matrix2)
print(""matrix multiplication\n"",np.multiply(matrix1,matrix2))
print(""matrix subtraction\n"",np.subtract(matrix1,matrix2))
print(""matrix division\n"",np.divide(matrix1,matrix2))
print(""matrix addition\n"",np.add(matrix1,matrix2))
print(""dot product matrix1\n"",np.dot(matrix1,matrix2))
print(""transpose"",np.transpose(matrix1))
print(""matrix squareroot\n"",np.sqrt(matrix1))
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 2
print(""matrix square\n"",np.square(matrix1))
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO1 has been
obtained.










Experiment No.: 2
Aim
Program to perform single value decomposition using numpy.
CO1
Use different python packages to perform numerical calculations, statistical computations and data
visualization.
Procedure
import numpy as np
mat=np.array([[5, 6, 4],[4, 5, 6],[3, 5, 6]])
U, S, VT = np.linalg.svd(mat)
print(""U matrix:\n"",U)
print(""S matrix:\n"",np.diag(S))
print(""VT\n"",VT)
reconstructed_mat=np.dot(U,np.dot(np.diag(S),VT))
print(""reconstructed_mat"",reconstructed_mat)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO1 has been
obtained.









Experiment No.: 3
Aim
Program to perform data visualisation using python library matplotlib.
CO1
Use different python packages to perform numerical calculations, statistical computations and data
visualization.
Procedure
import matplotlib.pyplot as plt
category= [""cat a"", ""cat b"", ""cat c""]
values= [1, 2, 3]
plt.bar(category,values)
plt.xlabel=""category""
plt.ylabel=""values""
plt.show()
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO1 has been
obtained.











Experiment No.: 4
Aim
Program to implement KNN classification using any standard dataset available in the public
domain and find the accuracy of algorithm (Iris Dataset).
CO2
Use different packages and frameworks to implement regression and classification algorithms.
Procedure
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.metrics import accuracy_score
iris=load_iris()
x=digits.data
y=digits.target
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)
knn=KNeighborsClassifier(n_neighbors=7)
knn.fit(x_train,y_train)
v=knn.predict(x_test)
res=accuracy_score(y_test,v)
print(""accuracy:"",res)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO2 has been
obtained.











Experiment No.: 5
Aim
Program to implement KNN classification using any standard dataset available in the public
domain and find the accuracy of algorithm (Load Digits).
CO2
Use different packages and frameworks to implement regression and classification algorithms.
Procedure
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_digits
from sklearn.metrics import accuracy_score
iris=load_digits()
x=digits.data
y=digits.target
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)
knn=KNeighborsClassifier(n_neighbors=7)
knn.fit(x_train,y_train)
v=knn.predict(x_test)
res=accuracy_score(y_test,v)
print(""accuracy:"",res)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO2 has been
obtained.













Experiment No.: 6
Aim
Program to implement Naive Bayes classification using any standard dataset available in the public
domain and find the accuracy of algorithm (Iris Dataset).
CO2
Use different packages and frameworks to implement regression and classification algorithms.
Procedure
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
iris=load_iris()
x=iris.data
y=iris.target
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)
naive_bayes = GaussianNB()
naive_bayes.fit(x_train,y_train)
v=naive_bayes.predict(x_test)
print(v)
result=accuracy_score(y_test,v)
print(""result"",result)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO2 has been
obtained.










Experiment No.: 7
Aim
Program to implement Naive Bayes classification using any standard dataset available in the public
domain and find the accuracy of algorithm (Breast Cancer Dataset).
CO2
Use different packages and frameworks to implement regression and classification algorithms.
Procedure
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score,classification_report
breast_cancer=load_breast_cancer()
x=breast_cancer.data
y=breast_cancer.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=40)
bc=GaussianNB()
bc.fit(x_train,y_train)
v=bc.predict(x_test)
print(v)
result = accuracy_score(y_test, v)
print(""result"", result)
report = classification_report(y_test,v,target_names=breast_cancer.target_names)
print(""classification_report\n"",report)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO2 has been
obtained.












Experiment No.: 8
Aim
Given one dimensional dataset represented with numpy array. Write a program to calculate slope
and intercept.
CO2
Use different packages and frameworks to implement regression and classification algorithms.
Procedure
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
x_value=np.array([64,75,68,73,78,82,76,85,71,88]).reshape(-1,1)
y_value=np.array([17,27,15,24,39,44,30,48,19,47])
lr=LinearRegression()
lr.fit(x_value,y_value)
slope=lr.coef_[0]
intercept=lr.intercept_
print(""slope"",slope)
print(""intercept"",intercept)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO2 has been
obtained.











Experiment No.: 9
Aim
Program to implement simple linear regression using any standard dataset available in the public
domain and find r2 score.
CO2
Use different packages and frameworks to implement regression and classification algorithms.
Procedure
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,classification_report
import matplotlib.pyplot as plt
data=pd.read_csv('Salary_Data.csv')
x=data['YearsExperience'].values.reshape(-1,1)
y=data['Salary'].values
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)
lr=LinearRegression()
lr.fit(x_train,y_train)
v=lr.predict(x_test)
result = r2_score(y_test,v)
print(""result"",result)
plt.scatter(x_test,y_test,color='black',label='datapoints')
plt.plot(x_test,v,color='blue', linewidth=3,label='Regression lines')
plt.xlabel('YearsExperience')
plt.ylabel('Salary')
plt.legend()
plt.show()
Output Screenshot
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 11
Result
The program was executed successfully and the output was obtained. Thus CO2 has been
obtained.









Experiment No.: 10
Aim
Program to implement Multiple Linear Regression techniques using any standard dataset available
in the public domain and evaluate its performance.
CO2
Use different packages and frameworks to implement regression and classification algorithms.
Procedure
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
ch = fetch_california_housing()
df = pd.DataFrame(data=ch.data,columns=ch.feature_names)
df['target'] = ch.target
x = df.drop('target',axis=1)
y = df['target']
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=40)
lr = LinearRegression()
lr.fit(x_train,y_train)
v = lr.predict(x_test)
result = mean_squared_error(y_test,v)
print(""mean_squared_error = "",result)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO2 has been
obtained.








Experiment No.: 11
Aim
Program to implement decision trees using any standard dataset available in the public domain and
find the accuracy of the algorithm (Iris Dataset).
CO3
Use different packages and frameworks to implement text classification using SVM and clustering
using K-means.
Procedure
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import plot_tree
from sklearn.metrics import accuracy_score,classification_report
from matplotlib import pyplot as plt
iris=load_iris()
x=iris.data
y=iris.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=39)
dt=DecisionTreeClassifier(max_depth=2)
dt.fit(x_train,y_train)
v=dt.predict(x_test)
print(v)
result=accuracy_score(y_test,v)
print(""result"",result)
report = classification_report(y_test,v,target_names=iris.target_names)
print(""classification_report\n"",report)
plt.figure(figsize=(10, 8))
features = iris.feature_names
classes = iris.target_names
plot_tree(dt, feature_names=features,class_names=classes,rounded=True,
filled=True,proportion=True)
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 14
plt.title(""Decision tree"")
plt.show()
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO3 has been
obtained.








Experiment No.: 12
Aim
Program to implement decision trees using any standard dataset available in the public domain and
find the accuracy of the algorithm (Breast Cancer Dataset).
CO3
Use different packages and frameworks to implement text classification using SVM and clustering
using K-means.
Procedure
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
from sklearn.tree import plot_tree
from sklearn.metrics import accuracy_score,classification_report
bc=load_breast_cancer()
x=bc.data
y=bc.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=39)
dt=DecisionTreeClassifier(max_depth=3)
dt.fit(x_train,y_train)
v=dt.predict(x_test)
result=accuracy_score(y_test,v)
print(""result"",result)
report = classification_report(y_test,v,target_names=bc.target_names)
print(""classification_report\n"",report)
plt.figure(figsize=(20, 18))
features = bc.feature_names
classes =bc.target_names
plot_tree(dt, feature_names=features,class_names=classes,rounded=True,filled=True,
proportion=True)
plt.title(""Decision tree breast_cancer"")
plt.show()
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 16
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO3 has been
obtained.












Experiment No.: 13
Aim
Program to implement k-means clustering technique using any standard dataset available in the
public domain (Iris Dataset).
CO3
Use different packages and frameworks to implement text classification using SVM and clustering
using K-means.
Procedure
from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
iris = load_iris()
x = iris.data
kmeans = KMeans(n_clusters=3,random_state=39)
kmeans.fit(x)
cluster_label = kmeans.labels_
print(""cluster labels\n"",cluster_label)
centroid = kmeans.cluster_centers_
print(""centroids\n"",centroid)
plt.scatter(x[:,0],x[:,1],c = cluster_label,cmap = 'viridis',marker = 'o',edgecolors='black')
plt.scatter(centroid[:,0],centroid[:,1],marker = '*',s=200,c='red',label='centroid')
plt.xlabel(iris.feature_names[0])
plt.ylabel(iris.feature_names[1])
plt.title('Kmeans cluster')
plt.legend()
plt.show()
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 18
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO3 has been
obtained.











Experiment No.: 14
Aim
Program to implement k-means clustering technique using any standard dataset available in the
public domain(Breast Cancer Dataset).
CO3
Use different packages and frameworks to implement text classification using SVM and clustering
using K-means.
Procedure
from sklearn.cluster import KMeans
from sklearn.datasets import load_breast_cancer
import matplotlib.pyplot as plt
bc = load_breast_cancer()
x = bc.data
kmeans = KMeans(n_clusters=3,random_state=40)
kmeans.fit(x)
cluster = kmeans.labels_
print(""cluster labels\n"",cluster)
centroid = kmeans.cluster_centers_
print(""centroid\n"",centroid)
plt.scatter(x[:,0],x[:,1],c=cluster,cmap='viridis',marker = 'o',edgecolor = 'red')
plt.scatter(centroid[:,0],centroid[:,1],s=100,c='blue',label='centroid')
plt.xlabel(bc.feature_names[0])
plt.ylabel(bc.feature_names[1])
plt.legend()
plt.show()
Output Screenshot
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 20
Result
The program was executed successfully and the output was obtained. Thus CO3 has been
obtained.









Experiment No.: 15
Aim
Program to implement text classification using support vector machine.
CO3
Use different packages and frameworks to implement text classification using SVM and clustering
using K-means.
Procedure
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report,accuracy_score
categories=['alt.atheism','soc.religion.christian','comp.graphics','sci.med']
twenty_train=fetch_20newsgroups(subset=""train"",categories=categories,shuffle=True,random_st
ate=42)
vectorizer=TfidfVectorizer()
x_train_tfidf=vectorizer.fit_transform(twenty_train.data)
y_train=twenty_train.target
x_train,x_test,y_train,y_test=train_test_split(x_train_tfidf,y_train,test_size=0.3,random_state=42
)
svm_classifier=SVC(kernel='linear',random_state=42)
svm_classifier.fit(x_train,y_train)
predictions=svm_classifier.predict(x_test)
accuracy_score=accuracy_score(y_test,predictions)
class_report=classification_report(y_test,predictions,target_names=twenty_train.target_names)
print(""Accuracy score"",accuracy_score)
print(""Classification report"",class_report)
new_data=[
 ""iam a devotee of lord christ"",
 ""i want a computer graphics""
]
x_new_tfidf = vectorizer.transform(new_data)
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 22
new_predictions= svm_classifier.predict(x_new_tfidf)
for i,text in enumerate(new_data):
 print(f""text: {text}"")
 predicted_category = twenty_train.target_names[new_predictions[i]]
 print(f""predicted category :{predicted_category}"")
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO3 has been
obtained.







Experiment No.: 16
Aim
Program on artificial neural network to classify images from any standard dataset in the public
domain using Keras framework.
CO4
Implement convolutional neural network algorithm using Keras framework.
Procedure
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
# Load the MNIST dataset
(X_train, y_train), (X_test, y_test) =mnist.load_data()
# Normalize pixel values to be between 0 and 1
X_train = X_train / 255.0
X_test = X_test / 255.0
# Flatten the images (convert 28x28 images to 1D vectors)
X_train = X_train.reshape(-1, 28 * 28)
print(X_train)
X_test = X_test.reshape(-1, 28 * 28)
print(X_train)
# One-hot encode the target labels
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
print(y_test)
# Create a simple feedforward neural network model
model=Sequential([
Dense(128, activation='relu', input_shape=(28 * 28,)),
Dense(68, activation='relu'),
Dense(10, activation='softmax')
])
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 24
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train,y_train, epochs=5 , batch_size=32, validation_split=0.2)
loss, accuracy= model.evaluate(X_test,y_test)
print(accuracy)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO4 has been
obtained.











Experiment No.: 17
Aim
Program to implement a simple web crawler using requests Library.
CO5
Implement programs for web data mining and natural language processing using NLTK.
Procedure
import requests
def simple_scraper(url):
 response=requests.get(url)
 if response.status_code==200:
 print(""Content:"")
 print(response.text)
 else:
 print(""Failed to fetch the page. Status code:"", response.status_code)
url_to_scrap=""https://ajce.in""
simple_scraper(url_to_scrap)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO5 has been
obtained.












Experiment No.: 18
Aim
Program to implement a simple web crawler and parse the content using BeautifulSoup.
CO5
Implement programs for web data mining and natural language processing using NLTK.
Procedure
import requests
from bs4 import BeautifulSoup
def simple_scraper(url):
 response=requests.get(url)
 if response.status_code==200:
 soup=BeautifulSoup(response.content, 'html.parser')
 print(""Title:"",soup.title.string)
 print(""Content:"")
 print(soup.get_text())
 else:
 print(""Failed to fetch the page. Status code:"", response.status_code)
url_to_scrap=""https://ajce.in""
simple_scraper(url_to_scrap)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO5 has been
obtained.












Experiment No.: 19
Aim
Implement problems on natural language processing – Part of Speech tagging, N-gram &amp;
smoothening and Chunking using NLTK.
CO5
Implement programs for web data mining and natural language processing using NLTK.
Procedure
import nltk
nltk.download('brown')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import word_tokenize
from nltk.util import ngrams
from nltk.corpus import brown
from nltk.chunk import RegexpParser
sentence = ""The quick brown fox jumps over the lazy dog""
tokens = word_tokenize(sentence)
print(tokens)
pos_tags = nltk.pos_tag(tokens)
print(""Part-of-Speech Tagging: "")
print(pos_tags)
text = brown.words(categories='news')[:1000]
bigrams = list(ngrams(text, 2))
freq_dist = nltk.FreqDist(bigrams)
print(""\n N-gram Analysis (Bigrams with Smoothing): "")
for bigram in bigrams:
print(f""{bigram}: {freq_dist[bigram]}"")
tagged_sentence = nltk.pos_tag(word_tokenize(""The quick brown fox jumps over the lazy dog""))
grammar = r""NP: {<DT>?<JJ>*<NN>}""
cp = RegexpParser(grammar)
result = cp.parse(tagged_sentence)
print(""\n Chunking with Regular Expressions and POS tags: "")
20MCA241 – Data Science Lab Dept. of Computer Applications
Amal Jyothi College of Engineering, Kanjirappally 28
print(result)
Output Screenshot
Result
The program was executed successfully and the output was obtained. Thus CO5 has been
obtained. "








